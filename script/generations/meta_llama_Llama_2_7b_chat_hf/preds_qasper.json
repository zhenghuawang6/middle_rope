{
    "3fad42be0fb2052bb404b989cc7d58b440cd23a0": "The article compares the proposed approach with two rule-based baselines: Unif and Stopword. Unif encoder randomly keeps tokens to generate keywords with the probability $\\delta $. The Stopword encoder keeps all tokens but drops stop words (e.g. 'the', 'a', 'or') all the time (or half of the time) to generate keywords.",
    "8bf7f1f93d0a2816234d36395ab40c481be9a0e0": "Yes, the authors do analyze transformer-based architectures in the article. They compare the performance of transformer-based models, including BERT and RoBERTa, with other neural network-based models for sentence pair modeling tasks. They find that transformer-based models generally perform better than other models on most datasets, and they provide a detailed analysis of the reasons behind this performance gap.",
    "0f12dc077fe8e5b95ca9163cea1dd17195c96929": "The 8,640 English sentences were generated by replacing INLINEFORM0 person INLINEFORM1 and INLINEFORM2 emotion word INLINEFORM3 variables with the values they can take. The full set of 8,640 sentences is referred to as the Equity Evaluation Corpus.",
    "518dae6f936882152c162058895db4eca815e649": "The UTCNN model has 3 convolutional layers and 1 fully connected layer, for a total of 4 layers.",
    "58ef2442450c392bfc55c4dc35f216542f5f2dbb": "Yes, the paper mentions that Macaw has been used for Wizard of Oz studies or intermediary-based information seeking studies. The authors provide a high-level overview of the architecture of Macaw for such setup, which consists of a conversational interface that supports multi-modal and mixed-initiative interactions in multiple devices, an intermediary (or the wizard) that receives the seeker's message and performs different information seeking actions with Macaw, and a log of all seeker-intermediary and intermediary-system interactions for further analysis.",
    "290ee79b5e3872e0496a6a0fc9b103ab7d8f6c30": "The three layers of the annotation scheme proposed in the article are:\n\n1. Level A: Offensive language detection - This layer distinguishes between offensive and non-offensive tweets.\n2. Level B: Categorization of Offensive Language - This layer categorizes the type of offense, including targeted insults and threats (TIN) and untargeted offenses (UNT).\n3. Level C: Offensive Language Target Identification - This layer identifies the target of the offensive language, including individual (IND), group (GRP), and other (OTH).",
    "ab9b0bde6113ffef8eb1c39919d21e5913a05081": "Their results show that error detection performance is substantially improved by making use of artificially generated data, created by any of the described methods. On the FCE dataset, the error detection system improved from 4.1% to 4.8% INLINEFORM0 . On the CoNLL 2014 dataset, the improvement was from 3.5% to 4.3% INLINEFORM0 .",
    "ff338921e34c15baf1eae0074938bf79ee65fdd2": "The baseline model used in the article is BioBERT BIBREF0, which is a pre-trained contextual word embedding model based on BERT.",
    "1b1a30e9e68a9ae76af467e60cefb180d135e285": "Their created dataset consists of 353 conversations from 40 speakers, amounting to 41 hours of audio data.",
    "dea9e7fe8e47da5e7f31d9b1a46ebe34e731a596": "The baseline classification uses a supervised machine learning algorithm.",
    "3355918bbdccac644afe441f085d0ffbbad565d7": "The supervised scores of the words are calculated using the following formula:\n\nmin(self score, min(context score1, ..., context scoreN))\n\nwhere self score is the polarity score of the target word, and context scorei is the polarity score of the word that appears in the ith context of the target word. The min function is used to select the minimum score from the set of context scores. This formula is used to capture the contextual information of the words and to improve the accuracy of the sentiment analysis.",
    "d9980676a83295dda37c20cfd5d58e574d0a4859": "The article introduces three data simulation techniques:\n\n1. Copy: The source side is a copy of the target-side data.\n2. Copy-marked: The source vocabulary is augmented with a copy of the target vocabulary, and the target words are marked with a special language identifier to avoid overlap.\n3. Copy-dummies: Not mentioned in the article.",
    "79a44a68bb57b375d8a57a0a7f522d33476d9f33": "The article mentions that the authors use BLEU score and qualitative metrics to evaluate their proposed model. However, it does not provide the specific qualitative metrics used for evaluation.",
    "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1": "The paper mentions the following features are used in the proposed model:\n\n1. Word segmentation information\n2. Morphological information (e.g. POS tags, gender, and number features)\n3. Morphological patterns\n4. Affixes (e.g. prefixes and suffixes)\n5. Contextual information (e.g. syntactic dependencies)\n\nThese features are used to capture the syntactic dependencies indicated by Part-Of-Speech (POS) tags, gender, and number features, and to exploit the morphological patterns and affixes in the Arabic language.",
    "8e52637026bee9061f9558178eaec08279bf7ac6": "The training data was translated using the machine translation platform Apertium.",
    "3116453e35352a3a90ee5b12246dc7f2e60cfc59": "The proposed model is compared to three baseline models:\n\n1. TF-IDF features in Section SECREF3 for traditional models.\n2. LSTM with self attention model (LSTM-self) has competitive results among this group, and this is the first study that compares and evaluates LSTM-based models on the medical term abbreviation disambiguation task.\n3. Topic Only setting on top of the base model, where only the topic-attention layer is added, and all the word embeddings were from the pre-trained Doc2vec model and were fine-tuned during back propagation.\n\nELMo Only, where the word embeddings of the base model are initialized from the pre-trained ELMo model, and no topic information is added.\n\nELMo+Topic, where the word embeddings from the sentences are computed from the pre-trained ELMo model, and the topic representations are from the pre-trained Doc2vec model.",
    "4e748cb2b5e74d905d9b24b53be6cfdf326e8054": "They used unigrams and pragmatic features, stylistic patterns, and patterns related to situational disparity.\n\nYes/No/Unanswerable:\nYes",
    "b970f48d30775d3468952795bc72976baab3438e": "They tackle the challenges of textual analysis, particularly when dealing with thick social and cultural concepts, such as hate speech. They highlight the difficulties of measuring these concepts, as they are culturally and socially situated, and may not be easily captured by computational methods. They also discuss the importance of considering the availability and accessibility of data sources, as well as the potential ethical concerns surrounding the use of born-digital data. Additionally, they mention the need to repurpose born-digital data, which may introduce biases into the inferences drawn, and the importance of understanding the context in which the data was created.",
    "c70bafc35e27be9d1efae60596bc0dd390c124c0": "Yes, the answers are double annotated. According to the article, the answers to the questions are formulated by domain experts with legal training, and then the answers are formulated again by at least two additional experts to ensure agreement."
}